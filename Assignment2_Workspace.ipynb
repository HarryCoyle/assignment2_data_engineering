{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0170a7c9-ec6b-4a6d-a5ce-9b8c25e7c709",
     "showTitle": true,
     "title": "Ranking by NA sales, showing 20 results"
    }
   },
   "outputs": [],
   "source": [
    "all_games_highest_global_sales = sales.orderBy(\"NA_Sales\", ascending=False).limit(20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9347eee9-6a28-4a28-a9cf-c996bfc5d095",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce363d60-6c8c-421f-8202-96cc045729bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType, DoubleType, BooleanType, DateType\n",
    "from pyspark.sql.functions import col, date_format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe3a1144-05a0-40e4-bf4c-7ab05358f263",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e25c248a-1d47-45f1-902d-8dde9bf27cb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mount(\n",
    "    source='wasbs://assignment-data@harryassignment2.blob.core.windows.net',\n",
    "    mount_point='/mnt/assignment-data',\n",
    "    extra_configs = {'fs.azure.account.key.harryassignment2.blob.core.windows.net': dbutils.secrets.get('harryassignmentscope', 'storageAccountKey')}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d467e9c-4059-43b1-a872-b464beaaaaa6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Read/loading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deecc87c-0fa1-469a-957c-2c14f83862c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"/mnt/assignment-data/raw-data/sales.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e8e05b3-90c9-40dd-8bd2-873e1e09d7bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Printing scheme of sales data, all strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f585e999-b1ba-4c4b-a4d1-637510239362",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ced9783-d809-4946-97cb-0e2f3fc021df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Changing data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7eac430-63cd-43b7-ab17-d1df80d68f53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales = sales \\\n",
    "    .withColumn(\"Ranking\", col(\"Rank\").cast(IntegerType())) \\\n",
    "    .withColumn(\"Release_Year\", col(\"Year\").cast(IntegerType())) \\\n",
    "    .withColumn(\"NA_Sales\", col(\"NA_Sales\").cast(DoubleType())) \\\n",
    "    .withColumn(\"EU_Sales\", col(\"EU_Sales\").cast(DoubleType())) \\\n",
    "    .withColumn(\"JP_Sales\", col(\"JP_Sales\").cast(DoubleType())) \\\n",
    "    .withColumn(\"Other_Sales\", col(\"Other_Sales\").cast(DoubleType())) \\\n",
    "    .withColumn(\"Global_Sales\", col(\"Global_Sales\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "287f991b-085f-4841-aacd-66014d99f0a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Printing scheme with new data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75978642-e982-4beb-b5cf-a685af067d82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fdc4cc4-480a-4f5a-9512-fda737495d29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exploring the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8e5a5fa-76bb-4b6c-82a4-8cac482dad1b",
     "showTitle": true,
     "title": "Ranking by global sales, showing 20 results"
    }
   },
   "outputs": [],
   "source": [
    "all_games_highest_global_sales = sales.orderBy(\"Global_Sales\", ascending=False).limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5702ffa1-31f8-4232-9953-e0207c37e54f",
     "showTitle": true,
     "title": "Ranking by NA sales, showing 20 results"
    }
   },
   "outputs": [],
   "source": [
    "all_games_highest_global_sales = sales.orderBy(\"NA_Sales\", ascending=False).filter(col(\"Genre\").contains(\"Sports\")).limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472106e3-b903-435d-a552-7a03d423c956",
     "showTitle": true,
     "title": "Ranking by EU sales, showing 20 results"
    }
   },
   "outputs": [],
   "source": [
    "all_games_highest_global_sales = sales.orderBy(\"EU_Sales\", ascending=False).filter(col(\"Year\").contains(\"2006\")).limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734988b1-1574-4090-90b7-4a525b0fba86",
     "showTitle": true,
     "title": "Ranking by JP sales, showing 20 results"
    }
   },
   "outputs": [],
   "source": [
    "all_games_highest_global_sales = sales.orderBy(\"JP_Sales\", ascending=False).filter(col(\"Platform\").contains(\"X360\")).limit(20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f467839a-2b65-4752-b1dc-6983f2596559",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a488220-57d9-4cb9-bbcc-cd821475cbee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Searching for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35aec97-06b2-45b2-8b05-ac9ae210e9e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count null values in each column\n",
    "null_counts = {col_name: sales.where(col(col_name).isNull()).count() for col_name in sales.columns}\n",
    "\n",
    "# Print the count of null values for each column\n",
    "for col_name, count in null_counts.items():\n",
    "    print(f\"Column '{col_name}' has {count} null values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1df90f24-4f8b-4b97-812d-aae5a0140424",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Found \"N/A\" stored in year of release for some records\n",
    "### Printing the the count of records with \"N/A\" for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9149c8d1-187a-4da0-8e63-534bd6b6c3b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count \"N/A\" values in each column\n",
    "na_counts = {col_name: sales.where(col(col_name) == \"N/A\").count() for col_name in sales.columns}\n",
    "\n",
    "# Print the count of \"N/A\" values for each column\n",
    "for col_name, count in na_counts.items():\n",
    "    print(f\"Column '{col_name}' has {count} 'N/A' values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d3b3a9a-fd03-4471-a4f4-69de57a1e071",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Removing records with \"N/A\" under year of release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e990045-4c78-41b6-a5f1-4bd1f357467a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales = sales.filter(col(\"Year\") != \"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dff16bf-06d7-45fe-8391-3018345056cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Removing columns with \"N/A\" under publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a982fe45-622e-4883-afc2-b72919798c2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales = sales.filter(col(\"Publisher\") != \"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f163da7-b9de-45b1-9727-b1a91fec5aa2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Checking for N/A columns again after cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45ef1df7-7d61-4e2c-9cad-bf0d9e6f4ebf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count \"N/A\" values in each column\n",
    "na_counts = {col_name: sales.where(col(col_name) == \"N/A\").count() for col_name in sales.columns}\n",
    "\n",
    "# Print the count of \"N/A\" values for each column\n",
    "for col_name, count in na_counts.items():\n",
    "    print(f\"Column '{col_name}' has {count} 'N/A' values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce30a9a5-5d21-4c28-8825-bd5359d3c9b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Writing the transformed data to Storage Account "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c6b7bce-10f6-4562-8c78-18c8853f6acd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales.write.option(\"header\",'true').csv(\"/mnt/assignment-data/transformed-data/sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b74af710-947c-4657-85b2-1ee9258c791e",
     "showTitle": true,
     "title": "Whoops"
    }
   },
   "outputs": [],
   "source": [
    "sales.write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/assignment-data/transformed-data/sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79b78e7f-0bb3-4e00-afff-0a66ff287529",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97324945-8de8-4f2e-9d2f-f289cfba4b93",
     "showTitle": true,
     "title": "Importing plotly"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9d25346-7b61-49eb-8d0e-99d720f06585",
     "showTitle": true,
     "title": "Genre popularity"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV files as Spark DataFrames\n",
    "sales = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/mnt/assignment-data/raw-data/sales.csv\")\n",
    "\n",
    "# Create temporary view for querying\n",
    "sales.createOrReplaceTempView(\"sales_view\")\n",
    "\n",
    "# Execute SQL queries to aggregate data\n",
    "query_result = spark.sql(\"\"\"\n",
    "SELECT genre,\n",
    "       COUNT(*) AS genre_count\n",
    "FROM sales_view\n",
    "GROUP BY genre\n",
    "ORDER BY genre_count DESC\n",
    "\"\"\")\n",
    "\n",
    "# Import Plotly\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a Pandas DataFrame for plotting\n",
    "pandas_df = query_result.toPandas()\n",
    "\n",
    "# Create the bar chart using Plotly\n",
    "fig = px.bar(pandas_df, x=\"genre\", y=\"genre_count\", color=\"genre\", title=\"Genre Popularity\")\n",
    "\n",
    "# Display the plot using display method\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbf4e0b-b796-4bff-a720-dfeca96f431f",
     "showTitle": true,
     "title": "Platform sales"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file as a Spark DataFrame\n",
    "sales = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/mnt/assignment-data/raw-data/sales.csv\")\n",
    "\n",
    "# Create temporary view for querying\n",
    "sales.createOrReplaceTempView(\"sales_view\")\n",
    "\n",
    "# Execute SQL queries to aggregate data\n",
    "query_result = spark.sql(\"\"\"\n",
    "SELECT Platform,\n",
    "       SUM(NA_Sales) AS NA_Sales,\n",
    "       SUM(EU_Sales) AS EU_Sales,\n",
    "       SUM(JP_Sales) AS JP_Sales,\n",
    "       SUM(Other_Sales) AS Other_Sales,\n",
    "       SUM(Global_Sales) AS Global_Sales\n",
    "FROM sales_view\n",
    "GROUP BY Platform\n",
    "ORDER BY Global_Sales DESC\n",
    "\"\"\")\n",
    "\n",
    "# Import Plotly Express for visualisation\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a Pandas DataFrame for plotting\n",
    "pandas_df = query_result.toPandas()\n",
    "\n",
    "# Create the bar chart using Plotly\n",
    "fig = px.bar(pandas_df, x=\"Platform\", y=[\"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"Global_Sales\"],\n",
    "             barmode=\"group\", title=\"Platform Sales\")\n",
    "\n",
    "# Display the plot\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "658fae75-be7e-4a46-bb67-7ee98b7561a1",
     "showTitle": true,
     "title": "Relationship between rank and global sales"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file as a Spark DataFrame\n",
    "sales = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/mnt/assignment-data/raw-data/sales.csv\")\n",
    "\n",
    "# Create temporary view for querying\n",
    "sales.createOrReplaceTempView(\"sales_view\")\n",
    "\n",
    "# Execute SQL query to select rank and global sales\n",
    "query_result = spark.sql(\"\"\"\n",
    "SELECT Rank, Global_Sales\n",
    "FROM sales_view\n",
    "ORDER BY Rank ASC\n",
    "\"\"\")\n",
    "\n",
    "# Import Plotly Express for visualisation\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a Pandas DataFrame for plotting\n",
    "pandas_df = query_result.toPandas()\n",
    "\n",
    "# Create the scatter plot using Plotly\n",
    "fig = px.scatter(pandas_df, x=\"Rank\", y=\"Global_Sales\", title=\"Global Sales vs. Rank\",\n",
    "                 labels={\"Rank\": \"Rank\", \"Global_Sales\": \"Global Sales\"},\n",
    "                 color=\"Global_Sales\", color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "# Customize marker size and opacity\n",
    "fig.update_traces(marker=dict(size=10, opacity=0.7))\n",
    "\n",
    "# Display the plot\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fe1849f-6532-4111-88c8-394f5369b63b",
     "showTitle": true,
     "title": "Distribution of game sales by genre"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file as a Spark DataFrame\n",
    "sales = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/mnt/assignment-data/raw-data/sales.csv\")\n",
    "\n",
    "# Create temporary view for querying\n",
    "sales.createOrReplaceTempView(\"sales_view\")\n",
    "\n",
    "# Query to get the total global sales by genre\n",
    "query_result_genre = spark.sql(\"\"\"\n",
    "    SELECT Genre, SUM(Global_Sales) AS Total_Global_Sales\n",
    "    FROM sales_view\n",
    "    GROUP BY Genre\n",
    "    ORDER BY Total_Global_Sales DESC\n",
    "\"\"\")\n",
    "\n",
    "# Convert the result to a Pandas DataFrame\n",
    "pandas_df_genre = query_result_genre.toPandas()\n",
    "\n",
    "# Create the pie chart using Plotly\n",
    "fig_genre = px.pie(pandas_df_genre, values='Total_Global_Sales', names='Genre', title='Distribution of Game Sales by Genre')\n",
    "fig_genre.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c765578d-fb76-4c2a-9885-be851f34922b",
     "showTitle": true,
     "title": "Relationship between year of release and global sales of games"
    }
   },
   "outputs": [],
   "source": [
    "# Read the CSV file as a Spark DataFrame\n",
    "sales = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/mnt/assignment-data/raw-data/sales.csv\")\n",
    "\n",
    "# Create temporary view for querying\n",
    "sales.createOrReplaceTempView(\"sales_view\")\n",
    "\n",
    "# Query to get the year of release, global sales, and platform of games\n",
    "query_result_year_sales_platform = spark.sql(\"\"\"\n",
    "    SELECT CAST(Year AS INT) AS Year, Global_Sales, Platform\n",
    "    FROM sales_view\n",
    "    WHERE Year IS NOT NULL AND Global_Sales IS NOT NULL AND Platform IS NOT NULL\n",
    "    ORDER BY Year ASC\n",
    "\"\"\")\n",
    "\n",
    "# Convert the result to a Pandas DataFrame\n",
    "pandas_df_year_sales_platform = query_result_year_sales_platform.toPandas()\n",
    "\n",
    "# Create the scatter plot using Plotly with color differentiation based on platform\n",
    "fig_year_sales_platform = px.scatter(pandas_df_year_sales_platform, x='Year', y='Global_Sales', \n",
    "                                     color='Platform', hover_name='Platform',\n",
    "                                     title='Relationship between Year of Release and Global Sales of Games',\n",
    "                                     trendline='ols')  # Trendline \n",
    "fig_year_sales_platform.show()  # Display the plot\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment2_Workspace",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
